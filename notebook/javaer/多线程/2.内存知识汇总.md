# 内存知识汇总

## 一、内存屏障(Memory Barrior)

### Intel 提供的屏障指令

- lfence：读
- sfence：写
- mfence：读与写

### 内存屏障分为两种：**Load Barrier** 和 **Store Barrier** 即读屏障和写屏障

- 内存屏障有两个作用
  - 阻止屏障两侧的指令重排序；
  - 强制把写缓冲区/调整缓冲区中的脏数据等写回主内存，记缓存中相应的数据失效；
- 对于 Load Barrier 来说，在指令前插入 Load Barrier，可以让调整缓存中的数据失效，强制重新从主内存中加载数据。
- 对于 Store Barrier 来说，在指令之后插入 Stroe Barrier，能让写入缓存中的最新数据更新写入主内存，让其它线程可见。

- **java 的内存屏障通常有四种**
  - **LoadLoad 屏障**：对于这样的语句 Load1; LoadLoad; Load2, 在 Load2 及后续读取的数据被访问之前,保证 Load1 要读取的数据被读取完毕。
  - **StoreStore 屏障**：对于这样的语句 Store1; StoreStore; Store2, 在 Store2 及后续写入操作执行这前，保证 Store1 的写入操作对其它处理器（或线程）可见。
  - **LoadStore 屏障**：对于这样的语句 Load1; LoadStore; Store2, 在 Store2 及后续写入操作被刷出前，保证 Load1 要读取的数据被读取完毕。
  - **StoreLoad 屏障**：对于这样的语句 Store1; LoadStore; Load2, 在 Load2 及后续所有读取操作执行前，保证 Store1 的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能

## 二、volatile 关键字

### volatile 是一个轻量级的 synchronize 锁

- 具备有序性及可见性。
- 但不具备原子性，但是对 long 与 double 是具备原子操作的。

### volatile 的内存屏障策略非常严格保守，非常悲观且毫毛安全感的心态

- 在每个 volatile 变量写操作前插入 StoreStore 屏障，在写操作后插入 StoreLoad 屏障；
- 在每个 volatile 变量读操作前插入 LoadLoad 屏障，在读操作后插入 LoadStore 屏障；

### volatile 性能

- volatile 的读性能消耗与普通变量几乎相同，但是写操作稍慢，因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行。

### **总结**

- 由于内存屏障的作用，避免了 volatile 变量和其它指令重排序、线程之间实现了通信，使得 volatile 表现出了锁的特性。

## 三、happens-before 原则

## 四、内存对齐

- cpu 把内存当成是一块一块的，块的大小可以是 2,4,8,16 个字节，因此 CPU 在读取内存的时候是一块一块进行读取的，块的大小称为（memory granularity）内存读取粒度。
  - 我们再来看看为什么内存不对齐会影响读取速度？
    - 假设 CPU 要读取一个 4 字节大小的数据到寄存器中（假设内存读取粒度是 4），分两种情况讨论：
      - 数据从 0 字节开始
      - 数据从 1 字节开始
    - 解析：当数据从 0 字节开始的时候，直接将 0-3 四个字节完全读取到寄存器，结算完成了。
      - 当数据从 1 字节开始的时候，问题很复杂，首先先将前 4 个字节读到寄存器，并再次读取 4-7 字节的数据进寄存器，接着把 0 字节，4,6,7 字节的数据剔除，最后合并 1,2,3,4 字节的数据进寄存器，对一个内存未对齐的寄存器进行了这么多额外操作，大大降低了 CPU 的性能。
  - 但是这还属于乐观情况，上文提到内存对齐的作用之一是平台的移植原因，因为只有部分 CPU 肯干，其他部分 CPU 遇到未对齐边界就直接罢工了。
